{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispielnotebook zur Bildklassifizierung\n",
    "\n",
    "### Umsetzung mit ChatGPT (GPT4-Basis) - Klassifizierung von Kleidungsstücken mit FashionMNIST Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zeitnahme zum Start der Ausführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensatz laden, untersuchen, Definition eines neuronalen Netzes\n",
    "\n",
    "Prompt: `Build a simple fully connected neural network using pytorch to classify images of clothing from the FashionMNIST dataset. Include a short overview of the different classes by showing exemplary images. Write multiple blocks of code that build on each other: (i) loading the data, (ii) examining the data and (iii) defining the network.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformations applied on each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to tensor format\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images\n",
    "])\n",
    "\n",
    "# Loading the training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Loading the test data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Creating data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Daten untersuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Class labels in FashionMNIST\n",
    "class_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "def show_images(images, labels, n=10):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(images[i].numpy().squeeze(), cmap='gray')\n",
    "        plt.title(class_labels[labels[i]])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Display images\n",
    "show_images(images, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definition eines Neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FashionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)  # Flatten the image and input to the first layer\n",
    "        self.fc2 = nn.Linear(256, 128)    # Second layer\n",
    "        self.fc3 = nn.Linear(128, 10)     # Output layer with 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the image\n",
    "        x = F.relu(self.fc1(x))  # Activation function for the first layer\n",
    "        x = F.relu(self.fc2(x))  # Activation function for the second layer\n",
    "        x = self.fc3(x)  # Output logits\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = FashionClassifier()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training und Evaluation des Modells\n",
    "\n",
    "Prompt: `Building on the previous code, train the model on the training split. Accelerate the training by using a GPU if one is available. Run an evaluation using macro-averaged F1-Score after each epoch, then display the training history (training and evaluation loss) after training has finished.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trainingsloop inkl. Validation nach jeder Epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the chosen device\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 10\n",
    "\n",
    "# To keep track of training and validation losses and F1-scores\n",
    "train_losses, val_losses, val_f1_scores = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    # Training loop\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        log_ps = model(images)  # Forward pass\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    else:\n",
    "        val_loss = 0\n",
    "        total_f1_score = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                log_ps = model(images)\n",
    "                val_loss += criterion(log_ps, labels).item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy = torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                \n",
    "                # Calculate F1 score\n",
    "                preds = top_class.view(-1).cpu().numpy()  # Get the predicted classes\n",
    "                true = labels.view(-1).cpu().numpy()  # Get the true classes\n",
    "                total_f1_score += f1_score(true, preds, average='macro')\n",
    "                num_batches += 1\n",
    "\n",
    "        # Calculate average losses and f1 score\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(test_loader))\n",
    "        val_f1_scores.append(total_f1_score/num_batches)\n",
    "\n",
    "        # Print training and validation results\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}.. '\n",
    "              f'Train loss: {train_losses[-1]:.3f}.. '\n",
    "              f'Val loss: {val_losses[-1]:.3f}.. '\n",
    "              f'Val F1: {val_f1_scores[-1]:.3f}')\n",
    "\n",
    "# Plot training and evaluation history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_f1_scores, label='Validation F1 Score')\n",
    "plt.title('Validation F1 Score by Epoch')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation nach Training mit Verwirrungsmatrix\n",
    "\n",
    "Prompt: `Create a confusion matrix displaying the model performance on the test set.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Containers for all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(len(class_labels)))\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition eines CNN (convolutional neural network)\n",
    "\n",
    "Prompt: `Define a new neural network using convolutional layers instead of linear ones. Then repeat the training and evaluation as before.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        # First convolutional layer: 1 input channel (grayscale image), 32 output channels, kernel size of 3\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        self.fc1 = nn.Linear(7*7*64, 128)  # after two pooling layers, the image size is reduced to 7x7\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Pooling layer with size 2 and stride 2\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # Flatten the tensor for the fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the CNN model\n",
    "cnn_model = FashionCNN().to(device)\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trainingsloop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the optimizer since we now have a different model\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_losses_cnn, val_losses_cnn, val_f1_scores_cnn = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    cnn_model.train()  # Training mode\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_ps = cnn_model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    total_f1_score = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        cnn_model.eval()\n",
    "        \n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            log_ps = cnn_model(images)\n",
    "            val_loss += criterion(log_ps, labels).item()\n",
    "            \n",
    "            _, predicted = torch.max(log_ps, 1)\n",
    "            preds = predicted.cpu().numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "            total_f1_score += f1_score(true, preds, average='macro')\n",
    "            num_batches += 1\n",
    "\n",
    "    train_losses_cnn.append(running_loss/len(train_loader))\n",
    "    val_losses_cnn.append(val_loss/len(test_loader))\n",
    "    val_f1_scores_cnn.append(total_f1_score/num_batches)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}.. '\n",
    "          f'Train loss: {train_losses_cnn[-1]:.3f}.. '\n",
    "          f'Val loss: {val_losses_cnn[-1]:.3f}.. '\n",
    "          f'Val F1: {val_f1_scores_cnn[-1]:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots und Evaluation durch Copy-Paste und leichte Änderungen des vorigen Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and evaluation history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses_cnn, label='Training loss (CNN)')\n",
    "plt.plot(val_losses_cnn, label='Validation loss (CNN)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_f1_scores_cnn, label='Validation F1 Score (CNN)')\n",
    "plt.title('Validation F1 Score by Epoch')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers for all predictions and true labels\n",
    "all_preds_cnn = []\n",
    "all_labels_cnn = []\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "cnn_model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = cnn_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds_cnn.extend(predicted.cpu().numpy())\n",
    "        all_labels_cnn.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels_cnn, all_preds_cnn, labels=range(len(class_labels)))\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and evaluation history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses_cnn, label='Training loss (CNN)')\n",
    "plt.plot(val_losses_cnn, label='Validation loss (CNN)')\n",
    "plt.plot(train_losses, label='Training loss', color=\"lightblue\")\n",
    "plt.plot(val_losses, label='Validation loss', color=\"xkcd:peach\")\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_f1_scores_cnn, label='Validation F1 Score (CNN)')\n",
    "plt.plot(val_f1_scores, label='Validation F1 Score', color=\"lightblue\")\n",
    "plt.title('Validation F1 Score by Epoch')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ende des Beispiels\n",
    "\n",
    "##### Zeitnahme zum Ende der Ausführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = datetime.now()\n",
    "duration = stop - start\n",
    "\n",
    "print(f\"Total time taken: {duration}.\")\n",
    "print(f\"This time was achieved with{'' if torch.cuda.is_available() else 'out'} GPU acceleration.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2020.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
