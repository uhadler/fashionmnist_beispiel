{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bildklassifikation mit Künstlicher Intelligenz\n",
    "\n",
    "\n",
    "<img src=\"./Bilder/MD_zentrum_hannover_RGB_300dpi.jpg\" alt=\"drawing\" height=\"300\"/>\n",
    "<img src=\"./Bilder/BMWK_Fz_MITTELSTAND%20DIGITAL_DTP_RGB_de.png\" alt=\"drawing\" height=\"300\"/>\n",
    "\n",
    "### Beispielhafte Umsetzung in einem Jupyter Notebook zur Klassifizierung von Kleidungsstücken mit FashionMNIST Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im vorigen Teil des Workshops haben wir die 5 Schritte und deren Umsetzung an einem Beispiel kennengelernt:\n",
    "- Datensammlung\n",
    "- Datenbeschriftung\n",
    "- Datenvorverarbeitung\n",
    "- Training und Evaluation\n",
    "- Implementierung\n",
    "\n",
    "In diesem Hands-On-Teil des Workshops setzen wir das Wissen praktisch um. Wir werden verschiedene einfache KI-Modelle trainieren, um Modeartikel aus dem FashionMNIST-Datensatz zu klassifizieren. Dabei handelt es sich um einen gängigen Datensatz für maschinelles Lernen, der aus 70 000 Schwarz-Weiß Bildern von Kleidungsstücken besteht und öffentlich zugänglich ist. \n",
    "\n",
    "Das Ziel ist, die 5 Schritte, die wir zuvor theoretisch behandelt haben, im Kontext einer konkreten KI-Anwendung zu erleben und Erfahrung in der Umsetzung zu sammeln. Sie werden zwei verschiedene neuronale Netze trainieren:\n",
    "1. ein einfaches neuronales Netzwerk, wie wir es im Theorieteil gesehen haben (auch Multi-Layer Perceptron genannt)\n",
    "2. ein faltendes NN (engl. Convolutional Neural Network), welches speziell für die Verarbeitung von Bildern entwickelt wurde\n",
    "\n",
    "In diesem Notebook werden Sie:\n",
    "- Eine explorative Analyse des Datensatzes durchführen\n",
    "- die Daten passend vorverarbeiten, um das KI-Training zu ermöglichen\n",
    "- zwei KI-Modelle (i) definieren und (ii) trainieren\n",
    "- die Leistung der Modelle evaluieren und vergleichen\n",
    "\n",
    "Bevor wir loslegen noch eine Einführung in das gezeigte Tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einführung in Google Colab\n",
    "\n",
    "Dieses Jupyter Notebook wird über Google Colab ausgeführt. Dies ist eine interaktive Umgebung, in der Sie Code ausführen und gleichzeitig Erklärungen, Texte und Diagramme sehen können - alles in einem Dokument. Hier sind die wichtigsten Schritte, um mit Colab zu arbeiten:\n",
    "\n",
    "- __Das Notebook ist in Zellen unterteilt__: Es gibt zwei Arten von Zellen: Textzellen (wie diese hier, die Erklärungen enthalten) und Codezellen (in denen Sie Code ausführen können). Jede Zelle ist wie ein Block, den Sie separat bearbeiten und ausführen können.\n",
    "- __Code ausführen__: Um den Code in einer Codezelle auszuführen, klicken Sie auf das kleine Wiedergabe-Dreieck (▶) links neben der Zelle, oder drücken Sie die Tastenkombination Shift + Enter. Das Ergebnis wird direkt unter der Zelle angezeigt. *Am schnellsten ist es, alle Zeilen direkt ausführen zu lassen* (mehr dazu im Folgenden).\n",
    "- __Zellen bearbeiten__: Sie können jede Zelle anklicken, um sie zu bearbeiten. Bei Textzellen können Sie den Text ändern, bei Codezellen den Code. Achtung: Sollten Sie den Code in einer Codezelle verändern, können Programmfehler auftreten. Nehmen Sie nur in gekennzeichneten Stellen Änderungen vor.\n",
    "- __Laufzeitumgebung verbinden__: Wenn Sie das Notebook öffnen, müssen Sie es mit einer Laufzeitumgebung verbinden, damit der Code ausgeführt werden kann. Klicken Sie dazu auf \"Verbinden\" oben rechts. Dadurch wird eine virtuelle Maschine gestartet, die Ihren Code ausführt.\n",
    "- __Beschleunigung des KI-Trainings__: Sie können kostenlos die Berechnungen beschleunigen lassen. Klicken Sie dazu oben auf den Reiter \"Laufzeit\" > \"Laufzeittyp ändern\" und wählen unter \"Hardwarebeschleiniger\" eine \"T4 GPU\" aus und drücken auf \"Speichern\". \n",
    "- __Fehlerbehebung__: Wenn etwas schiefgeht oder das Notebook nicht mehr reagiert, können Sie die Laufzeitumgebung neu starten. Klicken Sie dazu auf \"Laufzeit\" > \"Laufzeit neu starten\".\n",
    "\n",
    "Sobald sie mit der Laufzeit verbunden sind, können Sie die Zellen einzeln durchgehen und Code-Zeilen ausführen. Um *alle Code-Zellen direkt ausführen zu lassen*, können Sie (nach der Verbindung zu Laufzeit) oben auf den Reiter \"Laufzeit\" klicken und \"Alle ausführen\" auswählen. Dann finden alle Berechnungen so schnell es geht statt und Sie können die Erklärungen und Ergebnisse in aller Ruhe inspizieren.\n",
    "\n",
    "Dieses Notebook können Sie über den gleichen Link auch von Zuhause aus abrufen und durchklicken! Sollten Sie Änderungen vorgenommen haben, bleiben diese jedoch nicht bestehen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nutzen im folgenden die Programmiersprache Python. Zum Ausführen des Notebooks müssen Sie sich nur durchklicken und alle Codezellen ausführen (Dreieck drücken oder Shift+Enter). Falls Sie am Programmcode interessiert sind, können Sie den Code und insbesondere die darin enthaltenen Kommentare durchlesen. \n",
    "\n",
    "In Python lässt sich Programmcode und deren Kommentare wie folgt unterscheiden:\n",
    "\n",
    "\n",
    "```python\n",
    "# Dies ist ein Kommentar\n",
    "# Jeder Befehl in einer Zeile nach einem \"#\" wird nicht ausgeführt\n",
    "#print(\"Hallo, Welt!\") Diese Zeile wird nicht ausgeführt\n",
    "print(\"Los gehts!\")\n",
    "print(\"Ich wünsche viel Spaß bei dieser Übung!\") # Dies ist auch ein Kommentar!\n",
    "```\n",
    "\n",
    "Da Kommentare nur dazu da sind, Hinweise zu geben und den Code verständlicher zu machen, wäre das Ergebnis des hier aufgeführten Codes:\n",
    "\n",
    "```Los gehts!```\n",
    "\n",
    "```Ich wünsche viel Spaß bei dieser Übung!```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genutzte Softwarebibliotheken\n",
    "\n",
    "Im Folgenden werden mehrere Softwarebibliotheken der Programmiersprache Python genutzt:\n",
    "- __matplotlib__, __seaborn__: Darstellung von Graphen\n",
    "- __pytorch__, __torchvision__: Eine breit aufgestellte KI-Bibliothek von Meta. Wir nutzen diese, um die KI-Modelle zu definieren, zu trainieren, den Datensatz zu laden und die Daten vorzuverarbeiten.\n",
    "- __sklearn__ / __Scikit learn__: Von den meisten KI-Entwicklern genutzte KI-Bibliothek, mit der praktisch alles umgesetzt werden kann außer neuronalen Netzen.\n",
    "- __numpy__ / __np__: Komplexere Mathematik, mehrdimensionale Daten (Arrays)\n",
    "\n",
    "In der kommenden Code-Zelle werden die benötigten Bibliotheken und Funktionen importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#                                       #\n",
    "#                                       #\n",
    "#   IMPORT DER SOFTWAREBIBLIOTHEKEN     #\n",
    "#                                       #\n",
    "#                                       #\n",
    "#########################################\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Zeitnahme\n",
    "from datetime import datetime\n",
    "print(f\"Start der Ausführung: {datetime.now()}\")\n",
    "start = datetime.now()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritte 1 und 2: Datensammlung und -beschriftung\n",
    "\n",
    "Wir nutzen den _FashionMNIST_-Datensatz. Durch die große Bekanntheit in der Wissenschaft, können wir darauf kostenfrei zugreifen und ihn herunterladen. \n",
    "Das Nutzen von öffentlichen Datensätzen zum Trainieren eigener KI-Modelle wird oft praktiziert. \n",
    "Zwar \"überspringen\" wir damit quasi die ersten beiden Schritte, dies ist aber sinnvoll, um einen schnellen Einstieg zu ermöglichen. \n",
    "\n",
    "Um ein besseres Verständnis für den Datensatz zu erhalten, führen wir nun eine kurze explorative Datenanalyse durch. Darin werden Beispielbilder und Statistiken über den Datensatz aufgeführt.\n",
    "\n",
    "### Datensatz laden\n",
    " In der kommenden Code-Zelle wird der Datensatz heruntergeladen. Dies kann ein wenig dauern. Der Datensatz ist bereits in einen Trainingsdatensatz und Testdatensatz aufgeteilt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdatensatz herunterladen\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "# Testdatensatz herunterladen\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu verstehen, wie genau die Beobachtungen und Beschriftungen aussehen, lassen wir uns den ersten Datenpunkt inkl. Label anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste Beobachtung aus Datensatz anzeigen\n",
    "bild, label = train_data[0]\n",
    "\n",
    "print(bild)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeder Datenpunkt, also jede Beobachtung, ist im Datensatz dargestellt in 28x28 Zahlenwerten (Pixeln), während die dazugehörige Klasse zwischen bereits in Zahlen (zwischen 0 und 9) kodiert sind. Gleichzeitig sieht man, dass ein Bild für den Computer nicht direkt als Bild dargestellt wird! Dies gehen wir im nächsten Schritt an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorative Datenanalyse\n",
    "\n",
    "Als erster Schritt wird die Verteilung von Datenpunkten auf die verschiedenen Klassen untersucht. Wir stellen fest, dass das Verhältnis von Trainings- und Testdaten 85%-Trainingsdaten zu 15% Testdaten ist. Weiterhin sind für jede Klasse die gleiche Anzahl Datenpunkte vorhanden, der Datensatz ist also bzgl. der Klassen gut balanciert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durch unser Vorwissen zu dem Datensatz kennen wir bereits die enthaltenen Klassen\n",
    "# die Klassen sind im Datensatz schon kodifiziert und nur als Zahl angegeben\n",
    "# z.B. label 0 bezeichnet Klasse \"T-Shirt/Top\" und label 1 bezeichnet \"Hose\"\n",
    "klassen = ['T-shirt/Top', 'Hose', 'Pullover', 'Kleid', 'Mantel',\n",
    "                'Sandale', 'Hemd', 'Sneaker', 'Tasche', 'Stiefel']\n",
    "\n",
    "print(f\"Gesamtanzahl der Bilder im Testdatensatz: {len(test_data)}\")\n",
    "print(f\"Gesamtanzahl der Bilder im Trainingsdatensatz: {len(train_data)}\")\n",
    "\n",
    "\n",
    "def klassenstatistiken_berechnen_und_anzeigen(datensatz, klassen_labels):\n",
    "    # Zähle die Anzahl der Vorkommen jeder Klasse im Datensatz\n",
    "    label_zähler = Counter([label for _, label in datensatz])\n",
    "\n",
    "    # Berechne einige Statistiken\n",
    "    anzahl_bilder_total = len(datensatz)\n",
    "    klassen_stats = {}\n",
    "\n",
    "    for label, count in label_zähler.items():\n",
    "        klassenname = klassen[label]\n",
    "        klassen_stats[klassenname] = {\n",
    "            'Anzahl Bilder': count,\n",
    "            'Prozentsatz': (count / anzahl_bilder_total) * 100\n",
    "        }\n",
    "\n",
    "    # Ausgabe der Statistiken\n",
    "    for klassename, stats in klassen_stats.items():\n",
    "        print(f\"Klasse: {klassenname}\")\n",
    "        print(f\"  Anzahl Bilder: {stats['Anzahl Bilder']}\")\n",
    "        print(f\"  Prozentsatz: {stats['Prozentsatz']:.2f}%\")\n",
    "    \n",
    "    return klassen_stats\n",
    "\n",
    "# Aufruf der Funktion\n",
    "klassen_statistik = klassenstatistiken_berechnen_und_anzeigen(train_data, klassen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes können wir ein paar Bilder anschauen, um zu verstehen, welche Klassen vorhanden sind und wie die entsprechenden Bilder aussehen. \n",
    "Die Menge an Bildern wird durch ```ANZAHL_BEISPIELBILDER``` festgelegt. Daraufhin suchen wir zufällig Bilder aus dem Trainingsdatensatz aus und lassen diese Darstellen.\n",
    "Durch Erhöhen der Anzahl oder wiederholtes Ausführen der folgenden Code-Zelle können Sie also verschiedene Bilder erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANZAHL_BEISPIELBILDER = 15 # durch ändern dieser Zahl können Sie mehr oder weniger Beispielbilder erzeugen\n",
    "\n",
    "# generiert ANZAHL_BEISPIELBILDER zufällige Zahlen zwischen 0 und der Anzahl Bilder im Trainingsdatensatz\n",
    "bild_ids = [random.randint(0, len(train_data)) for _ in range(ANZAHL_BEISPIELBILDER)]\n",
    "\n",
    "# Funktion, die (anzahl) Bilder aus (datensatz) darstellt\n",
    "def bilder_zeigen(ids, datensatz):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    \n",
    "    for i, id in enumerate(ids):\n",
    "        # Bild und Beschriftung laden\n",
    "        bild, label = datensatz[id]\n",
    "        \n",
    "        # darstellen\n",
    "        plt.subplot(1, ANZAHL_BEISPIELBILDER, i+1)\n",
    "        plt.imshow(bild, cmap=\"gray\")\n",
    "        plt.title(klassen[label]) # die passende Klassenbezeichnung aussuchen!\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# erste ANZAHL_BEISPIELBILDER Bilder des Datensatzes anzeigen:\n",
    "bilder_zeigen(bild_ids, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Datenvorverarbeitung\n",
    "\n",
    "Der bereitgestellte Datensatz hat den Großteil der benötigten Verarbeitungsschritte schon vollzogen. Wie wir gesehen haben, sind z.B. die Klassennamen schon numerisch kodiert und die Bilder maschinenlesbar gespeichert.\n",
    "\n",
    "Wir definieren eine neue Transformationsfunktion, die die Bilder in einen konsistenten Wertebereich übertragt. Dies hilft der KI im Training, passende Muster einfacher zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transformation des Datentyps\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Übertragung in konsistenten Wertebereich\n",
    "])\n",
    "\n",
    "# Funktion, die Transformation auf Teilmenge des Datensatzes im Training anwendet\n",
    "def teilmenge_transformieren(teilmenge):\n",
    "    transformierte_tm = [(transform(bild), label) for bild, label in teilmenge]\n",
    "    bilder, labels = zip(*transformierte_tm)\n",
    "    bilder = torch.stack(bilder)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    #labels = torch.stack(labels)\n",
    "    return bilder, labels\n",
    "\n",
    "# Erstellung von DataLoadern\n",
    "# diese automatisieren viele sinnvolle Schritte, wenn wir Daten für das Training einlesen\n",
    "# und wendet u.a. unsere Transformation an\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=teilmenge_transformieren)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, collate_fn=teilmenge_transformieren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 4: Training und Evaluation\n",
    "\n",
    "In den vorigen Zellen haben wir den Datensatz geladen, untersucht und alle weiteren Vorbereitungen getroffen, um darauf KI-Systeme trainieren zu können. Im nächsten Schritt definieren wir unser erstes KI-Modell, ein neuronales Netzwerk aus drei Schichten, umgesetzt mit der Klasse ```nn.Linear```:\n",
    "- Die erste Schicht (aus 256 Neuronen) nimmt das Bild (alle Pixelwerte) als Input und berechnet erste Merkmale\n",
    "- Die zweite Schicht (128 Neuronen) verarbeitet diese Merkmale\n",
    "- Die dritte Schicht (10 Neuronen, sog. Output-Layer) klassifiziert das Bild. \n",
    "\n",
    "Genauer kann man sagen, dass jede Neuron einer Klasse zugeordnet ist und entscheidet, mit welcher Wahrscheinlichkeit das Bild der Klasse \"X\" angehört. Die Klasse mit der höchsten Wahrscheinlichkeit wird als Ergebnis akzeptiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition des 3-schichtigen NNs (MLPs)\n",
    "\n",
    "class FashionMLP(nn.Module):\n",
    "    # Initiierung der \"Bestandteile\", hier: 3 Schichten\n",
    "    # definiert alle Schichten des Netzwerks\n",
    "    def __init__(self):\n",
    "        super(FashionMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)  # erste Schicht\n",
    "        self.fc2 = nn.Linear(256, 128)    # zweite Schicht\n",
    "        self.fc3 = nn.Linear(128, 10)     # Output-Schicht\n",
    "\n",
    "    # Definition, wie die Bestandteile zusammenarbeiten\n",
    "    # x -> Inputbild \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Transformation der Datendarstellung (28x28 Matrix -> 1x748 Array)\n",
    "        x = F.relu(self.fc1(x))  # Verarbeitung erste Schicht inkl. ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc2(x))  # Verarbeitung zweite Schicht (inkl. Aktivierungsfunktion) \n",
    "        x = self.fc3(x)  # Dritte Schicht -> Output (10 Logits)\n",
    "        return x\n",
    "\n",
    "# nach der Definition erstellen wir das neuronale Netz\n",
    "model = FashionMLP()\n",
    "print(model)\n",
    "\n",
    "# überprüfen, ob Hardwarebeschleuniger verfügbar ist\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das jetzt erstellte neuronale Netz kann bereits Bilder klassifizieren. Da die Eigenschaften (Gewichte etc.) jedoch mit Zufallswerten starten und noch nicht trainiert wurden, ist dies wenig sinnvoll. Zu Demonstrationszwecken machen wir das jetzt trotzdem und überprüfen die Leistungsfähigkeit des jetzigen KI-Modells auf dem Testdatensatz durch den ```accuracy_score``` (kurz: Acc), den Prozentsatz der Datenpunkte, die unser Modell korrekt klassifiziert hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier speichern wir die Vorhersagen unserer KI und die wahren Beschriftungen\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images, labels in test_loader:\n",
    "        # Verschieben auf Hardwarebeschleuniger wenn nötig\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        ######################################################\n",
    "        ##                                                  ##\n",
    "        ##   Aufruf des KI Modells mit Bildern als Input    ##\n",
    "        ##                                                  ##\n",
    "        ######################################################\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Vorhersage ist Klasse mit höchster Wahrscheinlichkeit\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Speichern der Vorhersagen (auf CPU, d.h. nicht Hardwarebeschleuniger)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = accuracy_score(all_labels, all_preds)\n",
    "print(f'Anteil der Datenpunkte, die das untrainierte Modell korrekt erkannt hat: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleine durch Zufall kann das KI-Modell schon einige Bilder richtig erkennen.\n",
    "- Da in unserem Datensatz 10 Klassen vorhanden sind erwarten wir in etwa 10% (~0.1) korrekte Antworten\n",
    "- Diese Beobachtung ist jedoch zufallsbasiert und kann deshalb schwanken!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training und Evaluation des Modells\n",
    "\n",
    "Wir haben alle Voraussetzungen, um unser KI-Modell jetzt trainieren zu können:\n",
    "- Wir haben einen balancierten Datensatz inkl. Beschriftungen\n",
    "- Wir haben Vorverarbeitungsschritte eingeführt, um das Daten besser für die Maschine lesbar zu machen\n",
    "- Wir haben ein KI-Modell (neuronales Netz / Multi-Layer Perceptron) ausgesucht und definiert\n",
    "\n",
    "Um das Training zu starten, müssen wir noch weitere Entscheidungen treffen, wobei wir nicht auf alle genau eingehen. Wir definieren die Optimierungseigenschaften durch die Wahl einer Loss-Funktion und eines Optimierungsalgorithmus; da die Hintergründe extrem technisch werden, wird darauf nicht weiter eingegangen. Als nächstes müssen wir Evaluationsmetriken aussuchen, anhand derer wir die Leistungsfähigkeit der KI-Modelle abschätzen und vergleichen können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluationsmetriken\n",
    "\n",
    "Im Vorigen teil, haben wir schon den Anteil der Datenpunkte, die das untrainierte Modell korrekt erkannt hat, genutzt. Diesen sog. ```accuracy```-score werden wir als Vergleichswert weiterhin nutzen.\n",
    "\n",
    "Die Hauptmetrik wird der im Workshop vorgestellte ```F1-Score``` sein, da dieser eine bessere Abwägung zwischen Präzision und Sensitivität darstellt. Dies geschieht einfach durch Aufruf der ```f1_score()```. Sowohl für Accuracy als auch den F1 Score gilt, dass ein höherer Wert bessere Leistung andeutet und der höchstmögliche Wert ```1.0``` nicht übertroffen werden kann (und bedeutet, dass keine Fehler gemacht werden)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eigenschaften und Stellschrauben der Trainingsschleife\n",
    "\n",
    "Im Training wird die KI den Trainingsdatensatz typischerweise mehrfach durchlaufen, um die Eigenschaften der Daten besser zu verstehen und dadurch die Leistungsfähigkeit zu steigern. Diese Durchläufe nennt man Epochen, sie können diese durch Veränderung der Variable ```ANZAHL_EPOCHEN``` verändern.\n",
    "\n",
    "Um die Generalisierungsfähigkeit des KI-Modells einzuschätzen, nutzen wir nach jeder Epoche den Testdatensatz, um die Leistung des Models anhand der Evaluationsmetriken zu überprüfen. Nach jedem Durchlauf werden ein paar Statistiken ausgegeben, um den Trainingsfortschritt darzustellen:\n",
    "- ```train loss```, ```val loss``` beschreiben den \"Loss\" auf den Trainingsdaten und Testdaten und sind für dieses Notebook nicht zu wichtig\n",
    "- ```Val F1``` beschreibt den F1-Score auf den Testdaten (nach der Epoche)\n",
    "- ```Val Acc``` beschreibt den Accuracy-Score auf den Testdaten (nach der Epoche)\n",
    "\n",
    "Reminder: Sowohl für Accuracy als auch F1-Score sind höhere Werte besser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition der Optimierungsziele (Loss-Funktion und Optimierungsalgorithmus)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# wie oft der Trainingsdatensatz im Training wiederholt wird\n",
    "ANZAHL_EPOCHEN = 10\n",
    "\n",
    "# Hier behalten wir Statistiken im Auge\n",
    "train_losses, val_losses, val_f1_scores, val_acc_scores = [], [], [], []\n",
    "\n",
    "for epoch in range(ANZAHL_EPOCHEN):\n",
    "    running_loss = 0\n",
    "    model.train()  # KI-Modell in Trainingsmodus setzen\n",
    "    \n",
    "    ######################################################\n",
    "    ##                                                  ##\n",
    "    ##   Trainingsschleife: KI-Modell lernt hier dazu   ##\n",
    "    ##                                                  ##\n",
    "    ######################################################\n",
    "    for images, labels in train_loader:\n",
    "        # wenn möglich Berechnung auf Hardwarebeschleuniger\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(images)  # KI-Modell macht Vorhersage\n",
    "        loss = loss_func(log_ps, labels) # Vergleich mit Zielvariablen (Beschriftungen)\n",
    "        loss.backward()  # Rückverfolgung des Fehlers\n",
    "        optimizer.step()    # KI-Modell entsprechend des Fehlers verändern\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    # Evaluation nachdem der Trainigsdatensatz einmal durchlaufen wurde\n",
    "    # damit können wir Fortschritte im Training nachvollziehen\n",
    "    val_loss = 0\n",
    "    total_f1_score = 0\n",
    "    total_acc_score = 0\n",
    "    num_batches = 0\n",
    "        \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()  # KI-Modell in Inferenzmodus setzen\n",
    "            \n",
    "        for images, labels in test_loader:\n",
    "            # wenn möglich Berechnung auf Hardwarebeschleuniger\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            log_ps = model(images) # Vorhersage\n",
    "            val_loss += loss_func(log_ps, labels).item() # Loss speichern\n",
    "                \n",
    "            # Klasse mit höchster Wahrscheinlichkeit p extrahieren\n",
    "            ps = torch.exp(log_ps)\n",
    "            top_p, top_klasse = ps.topk(1, dim=1)\n",
    "            equals = top_klasse == labels.view(*top_klasse.shape)\n",
    "            \n",
    "            # Accuracy und F1 Scores berechnen\n",
    "            preds = top_klasse.view(-1).cpu().numpy()  # Vorhersagen extrahieren\n",
    "            true = labels.view(-1).cpu().numpy()  # Echte Werte (Beschriftungen) extrahieren\n",
    "            total_f1_score += f1_score(true, preds, average='macro')    # Berechnung F1-Score\n",
    "            total_acc_score += accuracy_score(true, preds)  # Berechnung Accuracy-Score\n",
    "            num_batches += 1\n",
    "\n",
    "        # Speichern der Statistiken für spätere Visualisierung\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(test_loader))\n",
    "        val_f1_scores.append(total_f1_score/num_batches)\n",
    "        val_acc_scores.append(total_acc_score/num_batches)\n",
    "\n",
    "        # Anzeige von Trainingsfortschritt inkl. Loss und Evaluation\n",
    "        print(f'Epoch {epoch+1}/{ANZAHL_EPOCHEN}.. '\n",
    "              f'Train loss: {train_losses[-1]:.3f}.. '\n",
    "              f'Val loss: {val_losses[-1]:.3f}.. '\n",
    "              f'Val F1: {val_f1_scores[-1]:.3f}.. '\n",
    "              f'Val Acc: {val_acc_scores[-1]:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selbst nach einer Epoche des Trainings kann das Modell bereits eine deutliche Leistungssteigerung im Vergleich mit dem untrainierten Modell aufweisen!\n",
    "\n",
    "Um den Trainingsverlauf genauer zu untersuchen, stellen wir die getrackten Statistiken nun graphisch dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen von Grafiken für Trainingshistorie, Evaluationshistorie\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Test loss')\n",
    "plt.title('Training und Test Loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(val_f1_scores, label='Test F1 Score')\n",
    "plt.title('Test F1 Score nach Epoche')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(val_acc_scores, label='Test Acc Score')\n",
    "plt.title('Test Accuracy Score nach Epoch')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Blick auf die Graphen sollte folgendes zeigen:\n",
    "- Trainingsloss sinkt stetig\n",
    "- Validierungsloss sinkt bis zu einem gewissen Punkt, ist volatiler\n",
    "- F1-Score und Accuracy verlaufen ähnlich, aber nicht genau\n",
    "- F1-Score und Accuracy korrelieren gut, aber nicht perfekt mit Validierungsloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation nach Training mit Verwirrungsmatrix\n",
    "\n",
    "Auch wenn das KI-Modell insgesamt gut zu funktionieren scheint, wollen wir dies weiter überprüfen. Mithilfe einer Verwirrungsmatrix können wir untersuchen, für welche Klassen die KI wie besonders genaue Vorhersagen machen kann und welche Klassen sie manchmal verwechselt.\n",
    "\n",
    "Die Verwirrungsmatrix lässt sich wie folgt lesen:\n",
    "- auf beiden Achsen ist jede unserer Klassen (z.B. \"Hemd\" oder \"Hose\") genau 1x aufgeführt\n",
    "- die Achsen sind in der gleichen Reihenfolge (oben-unten bzw. links-rechts)\n",
    "- die linke Achse (oben-unten) führt betitel die Klassen, wie sie im Datensatz beschriftet wurden (die echten Klassen)\n",
    "- die untere (links-rechts) Achse zeigt die von der KI vorhergesagten Klassen\n",
    "Jeder Eintrag in der Matrix zeigt nun, wie viele Beobachtungen (des Testdatensatzes) der Klasse L (links) von der KI als Klasse U (unten) eingestuft wurden. Ein paar Beispiele:\n",
    "\n",
    "Eintrag ganz oben links:\n",
    "- Klasse L = \"T-shirt/top\"\n",
    "- Klasse U = \"T-shirt/top\"\n",
    "- Eintrag = 874         (_Hinweis: diese Zahl hängt vom genauen Training ab und wird höchstwahrscheinlich nicht genau stimmen_)\n",
    "- Die KI hat also 874 Beobachtungen, die ein T-Shirt oder Top waren, auch korrekt als solches erkannt\n",
    "\n",
    "Eintrag ganz unten links:\n",
    "- Klasse L = \"Stiefel\"\n",
    "- Klasse U = \"T-short/Top\"\n",
    "- Eintrag = 1           (_Hinweis: diese Zahl hängt vom genauen Training ab und wird höchstwahrscheinlich nicht genau stimmen_)\n",
    "- Die KI hat also einen Datenpunkt, der eigentlich ein Bild von einem Stiefel ist, fälschlicherweise als T-Shirt oder Top eingestuft\n",
    "\n",
    "\n",
    "\n",
    "Da die Achsen in der gleichen Reihenfolge beschriftet sind, sind alle Datenpunkte, wo die KI korrekt lag, in der Hauptdiagonalen zu erkennen. Alle Einträge außerhalb dieser Diagonalen (ungleich 0) stellen dar, dass die KI Fehler gemacht hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern der Label\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluation\n",
    "model.eval()  # KI-Modell in Inferenzmodus setzen\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Berechnung der Verwirrungsmatrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(len(klassen)))\n",
    "\n",
    "# Grafische Darstellung der Verwirrungsmatrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=klassen, yticklabels=klassen)\n",
    "plt.xlabel('KI-Vorhersage')\n",
    "plt.ylabel('Echte Label (Beschriftungen)')\n",
    "plt.title('Verwirrungsmatrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Schlüsse können Sie anhand dieser Verwirrungsmatrix schließen?\n",
    "\n",
    "- Die Diagonale zeigt deutlich höhere Werte, als andere Einträge - ist das gut oder schlecht?\n",
    "- Treten bestimmte Fehler öfter auf als andere?\n",
    "- Verwechselt die KI manche Kleidungsstücke öfter miteinander, als andere?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Leistung unseres KI-Modells zu verbessern, gäbe es viele Möglichkeiten. Ist das Ergebnis denn überhaupt gut, oder haben wir z.B. bei der Auswahl und Definition des KI-Modells etwas falsch gemacht? Das überprüfen wir nun anhand eines weiteren KI-Modells, indem wir die gleiche Trainingsschleife mit einem auf Bildverarbeitung spezialisierten neuronalen Netz durchlaufen.\n",
    "\n",
    "\n",
    "### Training und Evaluation eines zweiten KI-Modells\n",
    "\n",
    "Ein normales neuronales Netzwerk, wie das MLP, was wir eben gerade definiert und trainiert haben, kann die Bilddaten nicht direkt verarbeiten. Statt die Dimensionalitäten (und damit Lokalisierung der einzelnen Pixel und Informationen) mit Inbretrachtung zu nehmen, mussten wir jedes Bild zuerst in eine eindimensionale Liste von ```28x28 = 784``` einträgen \"abflachen\". Somit ist es für dieses neuronale Netz deutlich schwieriger, lokale Eigenschaften zu erkennen.\n",
    "\n",
    "Ein CNN, ein sog. faltendes neuronales Netzwerk, versucht dieses Problem zu lösen. Statt nur mir einer flachen Liste zu arbeiten, sind solche neuronalen Netze darauf ausgelegt, einen Punkt und deren Umgebung zu verarbeiten. Dies wird für (praktisch) alle Bildpunkte wiederholt, wodurch eine Darstellung des Gesamtbildes erzeugt werden kann, die lokale Eigenschaften deutlich besser darstellen und verstehen kann. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definition des CNN\n",
    "\n",
    "In der folgenden Code-Zelle definieren wir nun das CNN, um das vorige Mudell zu erweitern. Das Modell besteht aus zwei Faltungsschichten (```nn.Conv2d```) und zwei Schichten, wie wir sie bisher kannten. Weiterhin nutzen wir Eine sog. Pooling-Schicht. Diese hilft dabei, dass die Faltungsschichten größeres rezeptives Feld haben, also kleine und größere räumliche Eigenschaften erkennen können. Zuletzt nutzen wir eine Dropout-Schicht, welche im Training die Generalisierungsfähigkeit verbessert, bei der späteren Nutzung des Modells jedoch keinen Einfluss mehr zeigt. \n",
    "\n",
    "Der Code beschreibt die genaue Definition:\n",
    "- Die erste Faltungsschicht nimmt das S/W-Bild als Eingabe und erzeugt 32 verschiedene Karten lokaler Merkmale.\n",
    "- Danach die Pooling-Schicht genutzt. Diese verringert die Bildgröße um den Faktor zwei, um die Merkmalsdichte zu erhöhen und das rezeptive Feld der nachfolgenden Schicht zu erweitern.\n",
    "- die zweite Faltungsschicht verarbeitet die 32 Merkmalskarten weiter und erzeugt insgesamt 64 noch komplere Merkmalskarten.\n",
    "- Darauf folgt wieder eine Pooling-Aktion\n",
    "Der Rest des CNNs funktioniert ähnlich dem MLP, welches wir zuvor gesehen haben:\n",
    "- Die gepoolten Merkmalskarten werden zu einem 1-dimensionalen Vektor abgeflacht (nun insgesamt 3136 Zahlenwerte)\n",
    "- eine \"normale\" Schicht (128 Neuronen) verarbeitet diese\n",
    "- Zuletzt verarbeitet die letzte Output-Schicht (10 Neuronen) diese wiederum, um die Wahrscheinlichkeiten je Klasse darzustellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    # Initiierung der \"Bestandteile\"\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        # zwei faltende Schichten mit 32 bzw. 64 Kanälen\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        # zwei \"normale\" Schichten, welche die zuvor berechneten Merkmale zur Klassifikation nutzen\n",
    "        self.fc1 = nn.Linear(7*7*64, 128) \n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        # Pooling-Schicht\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Dropout-Schicht\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    # Definition, wie Bestandteile zusammenarbeiten\n",
    "    # x -> Inputbild\n",
    "    def forward(self, x):\n",
    "        # Anwendung von Innen nach außen\n",
    "        # d.h. zuerst Conv1, dann ReLU, dann Pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # analog: zuerst Conv2, dann ReLU, dann Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # jetzt: abflachen des mehrdimensionalen Tensors in eine Dimension\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        # Berechnungen analog des MLPs was zuvor definiert wurde\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the CNN model\n",
    "cnn_model = FashionCNN().to(device)\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch dieses Modell wird vor dem Training genutzt, um die fehlende Leistung ohne Training darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier speichern wir die Vorhersagen unserer KI und die wahren Beschriftungen\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # cnn_model statt model\n",
    "    cnn_model.eval()\n",
    "    for images, labels in test_loader:\n",
    "        # Verschieben auf Hardwarebeschleuniger wenn nötig\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        ######################################################\n",
    "        ##                                                  ##\n",
    "        ##   Aufruf des KI Modells mit Bildern als Input    ##\n",
    "        ##  nach Modelldefinition: einziger Unterschied ist ##\n",
    "        ##     der Variablenname (cnn_model statt model)    ##\n",
    "        ##                                                  ##\n",
    "        ######################################################\n",
    "        outputs = cnn_model(images)\n",
    "        \n",
    "        # Vorhersage ist Klasse mit höchster Wahrscheinlichkeit\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Speichern der Vorhersagen (auf CPU, d.h. nicht Hardwarebeschleuniger)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = accuracy_score(all_labels, all_preds)\n",
    "print(f'Anteil der Datenpunkte, die das untrainierte Modell korrekt erkannt hat: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier ist die Leistung ohne Training erwartungsgemäß schlecht. Das wollen wir nun ändern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trainingsschleife des CNNs\n",
    "\n",
    "Die Trainingsschleife des CNN-Modells entspricht praktisch genau der Trainingsschleife des MLPs zuvor. \n",
    "\n",
    "In der folgenden Code-Zelle sind daher nur Veränderungen gegenüber der Trainingsschleife zuvor kommentiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss-Funktion muss nicht wieder definiert werden. Wir nutzen dieselbe wie zuvor :)\n",
    "\n",
    "# Der gleiche Optimierungsalgorithmus wird genutzt, optimiert jetzt aber die Parameter des cnn_model\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# wir müssen dies nicht definieren, wir trainieren gleich lang wie zuvor\n",
    "#ANZAHL_EPOCHEN = 10\n",
    "\n",
    "# wir nutzen eigene Variablen, um die Statistiken im Auge zu behalten\n",
    "# ... und später zw. Modellen vergleichen zu können.\n",
    "train_losses_cnn, val_losses_cnn, val_f1_scores_cnn, val_acc_scores_cnn = [], [], [], []\n",
    "\n",
    "for epoch in range(ANZAHL_EPOCHEN):\n",
    "    running_loss = 0\n",
    "    # aktuelles Modell in Trainingsmodus setzen, nicht das alte!\n",
    "    cnn_model.train()\n",
    "    \n",
    "    ######################################################\n",
    "    ##                                                  ##\n",
    "    ##   Trainingsschleife: KI-Modell lernt hier dazu   ##\n",
    "    ##                                                  ##\n",
    "    ######################################################\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_ps = cnn_model(images)  # cnn-Modell macht Vorhersage\n",
    "        loss = loss_func(log_ps, labels) \n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    val_loss = 0\n",
    "    total_f1_score = 0\n",
    "    total_acc_score = 0\n",
    "    num_batches = 0\n",
    "        \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        cnn_model.eval()  # cnn-Modell in Inferenzmodus setzen\n",
    "            \n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Vorhersage mit CNN-Modell machen\n",
    "            log_ps = cnn_model(images)\n",
    "            val_loss += loss_func(log_ps, labels).item()\n",
    "                \n",
    "            ps = torch.exp(log_ps)\n",
    "            top_p, top_klasse = ps.topk(1, dim=1)\n",
    "            equals = top_klasse == labels.view(*top_klasse.shape)\n",
    "            \n",
    "\n",
    "            preds = top_klasse.view(-1).cpu().numpy()\n",
    "            true = labels.view(-1).cpu().numpy()\n",
    "            total_f1_score += f1_score(true, preds, average='macro')\n",
    "            total_acc_score += accuracy_score(true, preds)\n",
    "            num_batches += 1\n",
    "\n",
    "        # Speichern der Statistiken für spätere Visualisierung mit neuen Variablen\n",
    "        train_losses_cnn.append(running_loss/len(train_loader))\n",
    "        val_losses_cnn.append(val_loss/len(test_loader))\n",
    "        val_f1_scores_cnn.append(total_f1_score/num_batches)\n",
    "        val_acc_scores_cnn.append(total_acc_score/num_batches)\n",
    "\n",
    "        # Anzeige von Trainingsfortschritt inkl. Loss und Evaluation\n",
    "        print(f'Epoch {epoch+1}/{ANZAHL_EPOCHEN}.. '\n",
    "              f'Train loss: {train_losses_cnn[-1]:.3f}.. '\n",
    "              f'Val loss: {val_losses_cnn[-1]:.3f}.. '\n",
    "              f'Val F1: {val_f1_scores_cnn[-1]:.3f}.. '\n",
    "              f'Val Acc: {val_acc_scores_cnn[-1]:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sehen kann, müssen - nach der Definition des CNN-Modells - nur sehr wenige Änderungen im Programmcode gemacht werden. \n",
    "\n",
    "Die Acc- und F1-Scores deuten schon auf eine bessere Leistungsfähigkeit im Vergleich mit dem vorigen Modell hin. Schauen wir uns den Trainingsverlauf an; auch hier können wir den Programmcode fast genau wiederverwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen von Grafiken für Trainingshistorie, Evaluationshistorie\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses_cnn, label='Training loss')\n",
    "plt.plot(val_losses_cnn, label='Test loss')\n",
    "plt.title('Training und Test Loss (CNN)')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(val_f1_scores_cnn, label='Test F1 Score')\n",
    "plt.title('Test F1 Score nach Epoche (CNN)')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(val_acc_scores_cnn, label='Test Acc Score')\n",
    "plt.title('Test Accuracy Score nach Epoch (CNN)')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann sehen, dass die Kurven sehr ähnlich aussehen, wie die des Modells davor. Hat sich da überhaupt etwas getan?\n",
    "\n",
    "Um das zu untersuchen, erzeugen wir mit der folgenden Code-Zelle neue Grafiken, in denen die jeweiligen Statistiken der beiden Modelle übereinander dargestellt werden. Dort gilt, dass die Kurven des CNN etwas dunkler dargestellt werden, als die des MLP, welches wir im ersten Teil des Notebooks trainiert haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and evaluation history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses_cnn, label='Training loss (CNN)')\n",
    "plt.plot(val_losses_cnn, label='Test loss (CNN)')\n",
    "plt.plot(train_losses, label='Training loss', color=\"lightblue\")\n",
    "plt.plot(val_losses, label='Test loss', color=\"xkcd:peach\")\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(val_f1_scores_cnn, label='Test F1 Score (CNN)')\n",
    "plt.plot(val_f1_scores, label='Test F1 Score', color=\"lightblue\")\n",
    "plt.title('Test F1 Score by Epoch')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(val_acc_scores_cnn, label='Test Acc Score (CNN)')\n",
    "plt.plot(val_acc_scores, label=\"Test Acc Score\", color=\"lightblue\")\n",
    "plt.title('Test Accuracy Score nach Epoch')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Grafik sind die Unterschiede deutlisch zu sehen:\n",
    "- die generellen Trends (groben Verläufe) aller Kurven sind ähnlich\n",
    "- Die Loss-Zahlen (sowohl für Trainings- als auch Testdatensatz) des CNN-Modells sind tendenziell niedriger als die des einfachen MLPs, d.h. es scheint besser zu sein\n",
    "- Diese Vermutung der besseren Leistung wird durch beide Evaluationsmetriken bestätigt:\n",
    "    - Das CNN-Modell klassifiziert einen größeren Anteil der Testdaten korrekt (höhere Accuracy)\n",
    "    - Das CNN-Modell erzielt einen höheren F1-Score\n",
    "\n",
    "\n",
    "Oft lässt sich eine interessante Beobachtung in der linken Grafik (Loss-Statistik auf Trainings- und Testdaten) machen: dass die Kurve der Loss-Statistik für das MLP im Training (hellblau) in den letzten Epochen ähnlich (oder sogar niedriger) ist, als die Kurve des CNN-Losses auf den Testdaten (dunkleres Orange). \n",
    "\n",
    "Hat diese eine Aussagekraft über die Leistung der beiden Modelle?\n",
    "Was kann der Grund für diese Beobachtung seien?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation des CNN-Modells mithilfe von Verwirrungsmatrix\n",
    "\n",
    "Anhand der soeben dargestellten Evaluationsmetriken konnten wir feststellen, dass das neu definierte CNN tatsächlich eine höhere Leistungsfähigkeit als das MLP hat. Dies bestätigt, dass Unterschiede in der Definition eines konkreten neuronalen Netzwerks einen Einfluss auf die Leistungsfähigkeit hat. Auch neuronale Netzwerke unterscheiden sich also nicht nur durch die Anzahl der Schichten und Neuronen!\n",
    "\n",
    "Analog zur Evaluation des MLPs untersuchen wir auch für das CNN, ob unser KI-Modell bzgl. der vorhandenen Klassen bestimmte Stärken oder Schwächen aufweist mithilfe einer Verwirrungsmatrix. \n",
    "\n",
    "Die folgende Code-Zelle wird zuerst die Verwirrungsmatrix für das CNN ausgeben, danach die bereits gezeigte Verwirrungsmatrix des MLP, damit diese vergleichbar sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern der Label\n",
    "all_preds_cnn = []\n",
    "all_labels_cnn = []\n",
    "\n",
    "# Evaluation\n",
    "cnn_model.eval()  # KI-Modell in Inferenzmodus setzen\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = cnn_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds_cnn.extend(predicted.cpu().numpy())\n",
    "        all_labels_cnn.extend(labels.cpu().numpy())\n",
    "\n",
    "# Berechnung der Verwirrungsmatrix\n",
    "conf_matrix_cnn = confusion_matrix(all_labels_cnn, all_preds_cnn, labels=range(len(klassen)))\n",
    "\n",
    "# Grafische Darstellung\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix_cnn, annot=True, fmt='d', cmap='viridis', xticklabels=klassen, yticklabels=klassen)\n",
    "plt.xlabel('KI-Vorhersage (CNN)')\n",
    "plt.ylabel('Echte Label (Beschriftungen)')\n",
    "plt.title('Verwirrungsmatrix (CNN)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Darstellung der Verwirrungsmatrix des MLP zu Vergleichszwecken\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=klassen, yticklabels=klassen)\n",
    "plt.xlabel('KI-Vorhersage (MLP)')\n",
    "plt.ylabel('Echte Label (Beschriftungen)')\n",
    "plt.title('Verwirrungsmatrix (MLP)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf den ersten Blick sehen die beiden Darstellungen sehr ähnlich aus: die Diagonale ist großteils gelb/grünlich und die Einträge außerhalb sind dunkellila mit kleinen bläulichen Flecken. Dies kommt daher, dass beide Modelle eine gute Leistung zeigen und den Großteil der Daten korrekt klassifizieren.\n",
    "\n",
    "Wenn man genauer hinschaut, lässt sich für die obere Matrix (CNN) feststellen:\n",
    "- sie hat tendenziell weniger bläuliche Flecken\n",
    "- die Einträge auf der Diagonale sind (im Durchschnitt) höher\n",
    "- Einträge außerhalb der Diagonale (im Durchschnitt) niedriger\n",
    "\n",
    "\n",
    "Oftmals sind die Zahlen der Einträge auf der Diagonalen für (Mantel, Mantel) und (Hemd, Hemd) ist deutlich größer als zuvor. Was lässt sich daraus für die Stärken und/oder Schwächen des CNN-Modells schließen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit\n",
    "\n",
    "Wir haben in diesem Notebook gesehen, wie schnell und einfach das im Workshop gezeigt Beispiel umgesetzt werden kann. Wir haben dabei...:\n",
    "- Einen öffentlich zugänglichen Datensatz genutzt, um Datensammlung und -beschriftung zu beschleunigen\n",
    "- Eine kurze explorative Datenanalyse durchgeführt, um Einblicke in den Datensatz zu erhalten\n",
    "- Eine Transformation der Datenstruktur genutzt, die die numerische Stabilität des Trainings unterstützt\n",
    "- Zwei KI-Modelle (ein MLP, ein CNN) definiert und...\n",
    "    - ... deren Leistungsfähigkeit untereinander anhand von den Metriken der Accuracy und des F1-Score verglichen\n",
    "    - ... mit Verwirrungsmatrizen gesondert auf Stärken und Schwächen geachtet, um die Fähigkeiten der Modelle besser zu verstehen\n",
    "- Dazu keine eigenen Rechenressourcen benötigt\n",
    "- Nur kostenfreie Tools genutzt\n",
    "\n",
    "Die Implementation in den Betriebsalltag wurde nicht explizit gezeigt. Die trainierten KI-Modelle lassen sich ähnlich wie andere Dateien auf dem Computer speichern und jederzeit in ein Programm laden. In diesem Programm können die Modelle dann genutzt werden, um Vorhersagen zu treffen; dies geschieht analog zu dem Code, mit dem die Verwirrungsmatrizen erstellt wurden.\n",
    "\n",
    "\n",
    "Zusammengefasst haben wir im Workshop einen fast vollständigen KI-Entwicklungszyklus durchlaufen - von der Datensammlung bis zur Evaluation. Dies zeigt, dass Künstliche Intelligenz und maschinelles Lernen nicht nur für Forschungseinrichtungen und große Unternehmen zugänglich ist, sondern auch für kleinere Projekte und Unternehmen. Die Verwendung von frei verfügbaren Tools und Datensätzen kann dabei die Einstiegshürden deutlich senken.\n",
    "\n",
    "Natürlich gibt es weitere Aspekte, die zu berücksichtigen sind, wenn KI-Modelle in der Praxis eingesetzt werden sollen. Beispiele sind eine kontinuierliche Überwachung der Modellleistung, Integration in bestehende Software oder Anpassungen bei Änderungen der Datenbasis. Mit dem hier vermittelten Wissen sind Sie hoffentlich bestens gerüstet, um weiter zu experimentieren, neue Anwendungsfälle zu erkunden und eigene KI-basierte Lösungen zu entwickeln!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = datetime.now()\n",
    "duration = stop - start\n",
    "\n",
    "print(f\"Gesamtdauer: {duration}.\")\n",
    "print(f\"Dieser Zeitaufwand wurde {'mit' if torch.cuda.is_available() else 'ohne'} Beschleunigung durch einen Grafikprozessor erreicht.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spielplatz für Begeisterte\n",
    "\n",
    "##### Definieren und Trainieren sie ihr eigenes Modell!\n",
    "\n",
    "In der nächsten Zelle wurde der Programmcode, um ein Modell wie hier gezeigt zu trainieren und die Verwirrungsmatrix zu berechnen in zwei Funktionen zusammengefasst.\n",
    "Diese können Sie einfach ausführen. In der Code-Zelle danach können Sie ihr eigenes Modell definieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_plot(model_to_train, anzahl_epochen):\n",
    "    # Definition der Optimierungsziele (Loss-Funktion und Optimierungsalgorithmus)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    model_to_train.to(device)\n",
    "    optimizer = optim.Adam(model_to_train.parameters(), lr=0.001)\n",
    "\n",
    "    # wie oft der Trainingsdatensatz im Training wiederholt wird\n",
    "    num_epochs = anzahl_epochen\n",
    "\n",
    "    # Hier behalten wir Statistiken im Auge\n",
    "    train_losses, val_losses, val_f1_scores, val_acc_scores = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        model_to_train.train()  # KI-Modell in Trainingsmodus setzen\n",
    "    \n",
    "        ######################################################\n",
    "        ##                                                  ##\n",
    "        ##   Trainingsschleife: KI-Modell lernt hier dazu   ##\n",
    "        ##                                                  ##\n",
    "        ######################################################\n",
    "        for images, labels in train_loader:\n",
    "            # wenn möglich Berechnung auf Hardwarebeschleuniger\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            log_ps = model_to_train(images)  # KI-Modell macht Vorhersage\n",
    "            loss = loss_func(log_ps, labels) # Vergleich mit Zielvariablen (Beschriftungen)\n",
    "            loss.backward()  # Rückverfolgung des Fehlers\n",
    "            optimizer.step()    # KI-Modell entsprechend des Fehlers verändern\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    \n",
    "        # Evaluation nachdem der Trainigsdatensatz einmal durchlaufen wurde\n",
    "        # damit können wir Fortschritte im Training nachvollziehen\n",
    "        val_loss = 0\n",
    "        total_f1_score = 0\n",
    "        total_acc_score = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model_to_train.eval()  # KI-Modell in Inferenzmodus setzen\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                # wenn möglich Berechnung auf Hardwarebeschleuniger\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                log_ps = model_to_train(images) # Vorhersage\n",
    "                val_loss += loss_func(log_ps, labels).item() # Loss speichern\n",
    "                \n",
    "                # Klasse mit höchster Wahrscheinlichkeit p extrahieren\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_klasse = ps.topk(1, dim=1)\n",
    "                equals = top_klasse == labels.view(*top_klasse.shape)\n",
    "            \n",
    "                # Accuracy und F1 Scores berechnen\n",
    "                preds = top_klasse.view(-1).cpu().numpy()  # Vorhersagen extrahieren\n",
    "                true = labels.view(-1).cpu().numpy()  # Echte Werte (Beschriftungen) extrahieren\n",
    "                total_f1_score += f1_score(true, preds, average='macro')    # Berechnung F1-Score\n",
    "                total_acc_score += accuracy_score(true, preds)  # Berechnung Accuracy-Score\n",
    "                num_batches += 1\n",
    "\n",
    "        # Speichern der Statistiken für spätere Visualisierung\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(test_loader))\n",
    "        val_f1_scores.append(total_f1_score/num_batches)\n",
    "        val_acc_scores.append(total_acc_score/num_batches)\n",
    "\n",
    "        # Anzeige von Trainingsfortschritt inkl. Loss und Evaluation\n",
    "        print(f'Epoch {epoch+1}/{ANZAHL_EPOCHEN}.. '\n",
    "              f'Train loss: {train_losses[-1]:.3f}.. '\n",
    "              f'Val loss: {val_losses[-1]:.3f}.. '\n",
    "              f'Val F1: {val_f1_scores[-1]:.3f}.. '\n",
    "              f'Val Acc: {val_acc_scores[-1]:.3f}')\n",
    "        \n",
    "    # Erstellen von Grafiken für Trainingshistorie, Evaluationshistorie\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(val_losses, label='Test loss')\n",
    "    plt.title('Training und Test Loss')\n",
    "    plt.legend(frameon=False)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(val_f1_scores, label='Test F1 Score')\n",
    "    plt.title('Test F1 Score nach Epoche')\n",
    "    plt.legend(frameon=False)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(val_acc_scores, label='Test Acc Score')\n",
    "    plt.title('Test Accuracy Score nach Epoch')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "def verwirrungsmatrix_berechnen(mymodel):\n",
    "    # Speichern der Label\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Evaluation\n",
    "    mymodel.eval()  # KI-Modell in Inferenzmodus setzen\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = mymodel(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Berechnung der Verwirrungsmatrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(len(klassen)))\n",
    "\n",
    "    # Grafische Darstellung der Verwirrungsmatrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=klassen, yticklabels=klassen)\n",
    "    plt.xlabel('KI-Vorhersage')\n",
    "    plt.ylabel('Echte Label (Beschriftungen)')\n",
    "    plt.title('Verwirrungsmatrix')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der nächsten Zelle ist bereits ein neues Modell definiert. Es stellt ein MLP dar, welches mehr Schichten und mehr Neuronen hat. Verändern Sie dieses Modell nach ihren Wünschen, Sie können natürlich auch ein komplett anderes KI-Modell definieren. \n",
    "- Dabei können jedoch Fehler auftreten und das KI-Modell ggf. nicht funktionieren!\n",
    "- Je größer und komplexer ein solches neuronales Netz wird, desto mehr Ressourcen werden für das Training gebraucht. Trainieren Sie sehr große neuronale Netze nur mit Hardwarebeschleunigern.\n",
    "\n",
    "Was denken Sie, wird dieses MLP aufgrund der höheren Anzahl an Schichten und Neuronen eine bessere Leistung zeigen, als das CNN? \n",
    "\n",
    "Oder denken Sie sich lieber ihr eigenes neuronales Netz aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IhrEigenesModell(nn.Module):\n",
    "    # Definition der Bestandteile\n",
    "    def __init__(self):\n",
    "        super(IhrEigenesModell, self).__init__()\n",
    "        self.fc0 = nn.Linear(28*28, 512)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(.33)\n",
    "\n",
    "    # Definition, wie die Bestandteile zusammenarbeiten\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.dropout(F.relu(self.fc0(x)))\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x) \n",
    "        return x\n",
    "\n",
    "# nach der Definition erstellen wir das neuronale Netz\n",
    "ihr_model = IhrEigenesModell()\n",
    "print(ihr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch Ausführen der nächsten Zelle wird ihr eigenes KI-Modell trainiert und die Verwirrungsmatrix berechnet. Sie können dabei z.B. die Anzahl der Epochen einfach ändern, indem Sie die Zeile ```ANZAHL_EPOCHEN = 10 ``` verändern. Dabei können Sie beliebige ganze Zahlen aussuchen, die größer als 0 sind. Eine höhere Anzahl an Epochen kann das Leistungsfähigkeit erhöhen, tut das aber nicht zwangsweise und bedeutet eine längere Zeit, bis das Training abgeschlossen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANZAHL_EPOCHEN = 10\n",
    "\n",
    "train_model_and_plot(model_to_train=ihr_model, anzahl_epochen=ANZAHL_EPOCHEN)\n",
    "verwirrungsmatrix_berechnen(ihr_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
